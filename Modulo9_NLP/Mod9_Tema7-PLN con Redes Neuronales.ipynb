{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLN con Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo el corpus A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_esA = pd.read_csv('train_es.tsv',delimiter='\\t',encoding='utf-8')\n",
    "corpus_dev_esA = pd.read_csv('dev_es.tsv',delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>Easyjet quiere duplicar el n√∫mero de mujeres p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>El gobierno debe crear un control estricto de ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>Yo veo a mujeres destruidas por acoso laboral ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>‚Äî Yo soy respetuoso con los dem√°s, s√≥lamente l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20007</td>\n",
       "      <td>Antonio Caballero y como ser de mal gusto e ig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>24996</td>\n",
       "      <td>@miriaan_ac @Linaveso_2105 @HumildesSquad_ C√ÅL...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>24997</td>\n",
       "      <td>@IvanDuque presidente en C√∫cuta , tenemos prob...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>24998</td>\n",
       "      <td>- Callat√© Visto Que Te Dejo En Putaüé§üé∂</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4467</th>\n",
       "      <td>24999</td>\n",
       "      <td>-¬øporque los hombres se casan con las mujeres?...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>25000</td>\n",
       "      <td>‚Äî No hay nada m√°s lento que un caracol. ‚Äî C√°ll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4469 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  TR  AG\n",
       "0     20001  Easyjet quiere duplicar el n√∫mero de mujeres p...   1   0   0\n",
       "1     20002  El gobierno debe crear un control estricto de ...   1   0   0\n",
       "2     20003  Yo veo a mujeres destruidas por acoso laboral ...   0   0   0\n",
       "3     20004  ‚Äî Yo soy respetuoso con los dem√°s, s√≥lamente l...   0   0   0\n",
       "4     20007  Antonio Caballero y como ser de mal gusto e ig...   0   0   0\n",
       "...     ...                                                ...  ..  ..  ..\n",
       "4464  24996  @miriaan_ac @Linaveso_2105 @HumildesSquad_ C√ÅL...   1   1   1\n",
       "4465  24997  @IvanDuque presidente en C√∫cuta , tenemos prob...   1   0   1\n",
       "4466  24998              - Callat√© Visto Que Te Dejo En Putaüé§üé∂   0   0   0\n",
       "4467  24999  -¬øporque los hombres se casan con las mujeres?...   1   0   0\n",
       "4468  25000  ‚Äî No hay nada m√°s lento que un caracol. ‚Äî C√°ll...   0   0   0\n",
       "\n",
       "[4469 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza en los datos\n",
    "* Cambiar todas las palabras de may√∫sculas a min√∫sculas\n",
    "* Se han eliminado las '@' de @USUARIO con el fin de facilitar el etiquetado morfol√≥gico\n",
    "* Quitar los links \n",
    "* Quitar los emojis\n",
    "* Eliminar las stopwords\n",
    "* Se han reemplazado todos los n√∫meros por el s√≠mbolo '0'\n",
    "* Quitar los signos de puntuaci√≥n y quitar espacios (tabuladores, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_URL=\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\"\n",
    "\n",
    "def procesar(file, namefile):    \n",
    "    file[file.columns[1]] = [clean_text(i) for i in file[file.columns[1]]]    \n",
    "    file.to_csv(namefile, sep='\\t', encoding='utf-8', index=False)\n",
    "    return file\n",
    "    \n",
    "def clean_text(text):\n",
    "    text = text.lower()   \n",
    "    #text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \"@USUARIO\", text)\n",
    "    text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \" \", text)\n",
    "    text=re.sub(pattern_URL, \" \", text)\n",
    "    \n",
    "    text= remove_emoji(text)\n",
    "    text= remove_stopwords(text)\n",
    "    text=re.sub(\"\\d+\", \"0\", text)\n",
    "    # text=re.sub(\"\\d+\", \" \", text)\n",
    "    \n",
    "    text=re.sub(r\" +\", \" \", re.sub(r\"\\t\", \" \", re.sub(r\"\\n+\", \"\\n\", re.sub('(?:[.,\\/!$%?¬ø?!¬°\\^&\\*;:{}=><\\-_`~()‚Äù‚Äú\"\\'\\|])', \" \",text))))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):    \n",
    "    stopwords=set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "    for i in stopwords:\n",
    "        text = re.sub(r\"\\b%s\\b\" % i, \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs                               \n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"\\U00002702-\\U000027B0\"\n",
    "                               \"\\U000024C2-\\U0001F251\"\n",
    "                               \"\\U0001f926-\\U0001f937\"\n",
    "                               \"\\u200d\"\n",
    "                               \"\\u2640-\\u2642\"\n",
    "                               \"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "                               \"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "                               \"\\U0001F600-\\U0001F64F\"\n",
    "                               \"\\U0001F1F2\"\n",
    "                               \"\\U0001F1F4\"\n",
    "                               \"\\U0001F620\"\n",
    "                               \"]+\", flags=re.UNICODE)   \n",
    "    text = emoji_pattern.sub(r'', text) # no emoji\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando el corpus ya procesado A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_esA = procesar(corpus_train_esA, \"train_es_cleanA.tsv\")\n",
    "corpus_dev_esA = procesar(corpus_dev_esA, \"dev_es_cleanA.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>easyjet quiere duplicar n√∫mero mujeres piloto ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>gobierno debe crear control estricto inmigraci...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>veo mujeres destruidas acoso laboral callejero...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>‚Äî respetuoso dem√°s s√≥lamente recuerdo si escor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20007</td>\n",
       "      <td>antonio caballero ser mal gusto ignorante vez ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>24996</td>\n",
       "      <td>c√°llateeee zorra ahre #cnco #bestboyband #ihea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>24997</td>\n",
       "      <td>presidente c√∫cuta problemas venezolanos disput...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>24998</td>\n",
       "      <td>callat√© visto dejo puta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4467</th>\n",
       "      <td>24999</td>\n",
       "      <td>hombres casan mujeres cabras saben fregar platos</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>25000</td>\n",
       "      <td>‚Äî lento caracol ‚Äî c√°llate hijo puta dices blac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4469 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  TR  AG\n",
       "0     20001  easyjet quiere duplicar n√∫mero mujeres piloto ...   1   0   0\n",
       "1     20002  gobierno debe crear control estricto inmigraci...   1   0   0\n",
       "2     20003  veo mujeres destruidas acoso laboral callejero...   0   0   0\n",
       "3     20004  ‚Äî respetuoso dem√°s s√≥lamente recuerdo si escor...   0   0   0\n",
       "4     20007  antonio caballero ser mal gusto ignorante vez ...   0   0   0\n",
       "...     ...                                                ...  ..  ..  ..\n",
       "4464  24996  c√°llateeee zorra ahre #cnco #bestboyband #ihea...   1   1   1\n",
       "4465  24997  presidente c√∫cuta problemas venezolanos disput...   1   0   1\n",
       "4466  24998                            callat√© visto dejo puta   0   0   0\n",
       "4467  24999   hombres casan mujeres cabras saben fregar platos   1   0   0\n",
       "4468  25000  ‚Äî lento caracol ‚Äî c√°llate hijo puta dices blac...   0   0   0\n",
       "\n",
       "[4469 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leyendo el corpus ya procesado-limpio A\n",
    "\n",
    "train_idA = corpus_train_esA[corpus_train_esA.columns[0]]\n",
    "X_train_textA = corpus_train_esA[corpus_train_esA.columns[1]].fillna(' ')\n",
    "y_train_hsA = corpus_train_esA[corpus_train_esA.columns[2]]\n",
    "\n",
    "test_idA = corpus_dev_esA[corpus_train_esA.columns[0]]\n",
    "X_test_textA = corpus_dev_esA[corpus_dev_esA.columns[1]].fillna(' ')\n",
    "y_test_hsA = corpus_dev_esA[corpus_dev_esA.columns[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4469 4469\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "print( len(X_train_textA), len(y_train_hsA) )\n",
    "\n",
    "print( len(X_test_textA), len(y_test_hsA) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando los CountVectorizer para construir la matriz termino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4469, 1775)\n",
      "(500, 1775)\n"
     ]
    }
   ],
   "source": [
    "cvectorizer = CountVectorizer(\n",
    "    # lowercase=True,\n",
    "    #stop_words=[word.decode('utf-8') for word in nltk.corpus.stopwords.words('spanish')],\n",
    "    #token_pattern=r'\\b\\w+\\b', #selects tokens of 2 or more alphanumeric characters \n",
    "    ngram_range=(1,3),#n-grams de palabras n = 1 a n = 3 (unigramas, bigramas y trigramas)\n",
    "    min_df=5,#ignorando los t√©rminos que tienen una frecuencia de documento estrictamente inferior a 5\n",
    ").fit(X_train_textA)\n",
    "\n",
    "X_train_cvectorized = cvectorizer.transform(X_train_textA).toarray()\n",
    "print(X_train_cvectorized.shape)\n",
    "\n",
    "X_test_cvectorized = cvectorizer.transform(X_test_textA).toarray()\n",
    "print(X_test_cvectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4469, 1775)\n",
      "(500, 1775)\n"
     ]
    }
   ],
   "source": [
    "tvectorizer = TfidfVectorizer(\n",
    "    # lowercase=True,\n",
    "    #stop_words=[word.decode('utf-8') for word in nltk.corpus.stopwords.words('spanish')],\n",
    "    #token_pattern=r'\\b\\w+\\b', #selects tokens of 2 or more alphanumeric characters \n",
    "    ngram_range=(1,3),#n-grams de palabras n = 1 a n = 3 (unigramas, bigramas y trigramas)\n",
    "    min_df=5,#ignorando los t√©rminos que tienen una frecuencia de documento estrictamente inferior a 5\n",
    ").fit(X_train_textA)\n",
    "\n",
    "X_train_tvectorized = tvectorizer.transform(X_train_textA).toarray()\n",
    "print(X_train_tvectorized.shape)\n",
    "\n",
    "X_test_tvectorized = tvectorizer.transform(X_test_textA).toarray()\n",
    "print(X_test_tvectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Perceptr√≥n\n",
    "   \n",
    "   https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptr√≥n Multicapa (Multi-Layer Perceptron, MLP) \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=500, alpha=0.0001,\n",
    "                    solver='adam', random_state=21,tol=0.000000001)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(6,6,6,6),solver='lbfgs',max_iter=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Accuracy mlp1 cv 0.756\n",
      "\t F1-score mlp1 cv 0.7288888888888888\n",
      "\t Accuracy mlp1 tfidv 0.74\n",
      "\t F1-score mlp1 tfidv 0.7045454545454545\n"
     ]
    }
   ],
   "source": [
    "mlp1.fit( X_train_cvectorized, y_train_hsA)\n",
    "predictions1 = mlp1.predict(X_test_cvectorized)\n",
    "\n",
    "print('\\t', 'Accuracy mlp1 cv', accuracy_score(y_test_hsA, predictions1))\n",
    "print('\\t', 'F1-score mlp1 cv', f1_score(y_test_hsA, predictions1))\n",
    "\n",
    "######\n",
    "\n",
    "mlp1.fit( X_train_tvectorized, y_train_hsA)\n",
    "predictions1 = mlp1.predict(X_test_tvectorized)\n",
    "\n",
    "print('\\t', 'Accuracy mlp1 tfidv', accuracy_score(y_test_hsA, predictions1))\n",
    "print('\\t', 'F1-score mlp1 tfidv', f1_score(y_test_hsA, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Accuracy mlp2 cv 0.742\n",
      "\t F1-score mlp2 cv 0.7139689578713968\n",
      "\t Accuracy mlp2 tfidv 0.754\n",
      "\t F1-score mlp2 tfidv 0.7421383647798743\n"
     ]
    }
   ],
   "source": [
    "mlp2.fit( X_train_cvectorized, y_train_hsA)\n",
    "predictions2 = mlp2.predict(X_test_cvectorized)\n",
    "\n",
    "print('\\t', 'Accuracy mlp2 cv', accuracy_score(y_test_hsA, predictions2))\n",
    "print('\\t', 'F1-score mlp2 cv', f1_score(y_test_hsA, predictions2))\n",
    "\n",
    "######\n",
    "\n",
    "mlp2.fit( X_train_tvectorized, y_train_hsA)\n",
    "predictions2 = mlp2.predict(X_test_tvectorized)\n",
    "\n",
    "print('\\t', 'Accuracy mlp2 tfidv', accuracy_score(y_test_hsA, predictions2))\n",
    "print('\\t', 'F1-score mlp2 tfidv', f1_score(y_test_hsA, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las RN son sensibles a la escala de los datos de entrada, especialmente cuando se utilizan las funciones de activaci√≥n sigmoide (por defecto) o tanh. Puede ser una buena pr√°ctica reescalar los datos al rango de 0 a 1, tambi√©n llamado normalizaci√≥n. Podemos normalizar f√°cilmente el conjunto de datos utilizando la clase de preprocesamiento MinMaxScaler de la biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizacion de los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train_cvectorized)\n",
    "X_test = scaler.fit_transform(X_test_cvectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Accuracy mlp2 0.714\n",
      "\t F1-score mlp2 0.6697459584295613\n"
     ]
    }
   ],
   "source": [
    "mlp2.fit( X_train, y_train_hsA)\n",
    "predictions2 = mlp2.predict(X_test)\n",
    "\n",
    "print('\\t', 'Accuracy mlp2', accuracy_score(y_test_hsA, predictions2))\n",
    "print('\\t', 'F1-score mlp2', f1_score(y_test_hsA, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales recurrentes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>¬øQu√© es Keras?</b>\n",
    "\n",
    "Keras es una biblioteca de Python minimalista para Deep Learning que puede funcionar sobre Theano o TensorFlow. Fue desarrollada con el objetivo de que los modelos de Deep Learning sean tan r√°pidos y f√°ciles tanto para la investigaci√≥n como el desarrollo. Funciona en Python 2.7 o 3.6 y se puede ejecutar sin problemas sobre las GPU y las CPU. Es libre bajo una licencia del MIT. Keras fue desarrollado por Francois Chollet, un ingeniero de Google que utiliza cuatro principios rectores:\n",
    "<ul>\n",
    "    <li><b>Modularidad</b>: Un modelo puede entenderse s√≥lo como una secuencia o como un gr√°fico. Todas las caracter√≠sticas de un modelo de aprendizaje profundo son componentes discretos que pueden combinarse de manera arbitraria.</li>\n",
    "    <li><b>Minimalismo</b>: La biblioteca proporciona lo justo para lograr un resultado, sin florituras y maximizando la legibilidad.</li>\n",
    "    <li><b>Extensibilidad</b>: Los nuevos componentes son intencionalmente f√°ciles de a√±adir y usar dentro del marco destinado a que los desarrolladores prueben y exploren nuevas ideas.</li>\n",
    "    <li><b>Python</b>: No hay modelos separados con formatos personalizados. Todo es nativo de Python.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<b>Construya modelos de Deep Learning con Keras</b>\n",
    "\n",
    "El enfoque de Keras es la idea de un modelo. El tipo principal de modelo es una secuencia de capas llamada Secuencial que es una pila lineal de capas. Se crea un Secuencial y se le a√±aden capas en el orden en que desea que se realice el c√°lculo. Una vez definido, se compila el modelo que utiliza el marco subyacente para optimizar el c√°lculo que se va a realizar. En este se puede especificar la funci√≥n de p√©rdida y el optimizador a utilizar.\n",
    "\n",
    "Una vez compilado, el modelo debe ajustarse a los datos. Esto se puede hacer con un lote de datos o por el anillo o el r√©gimen de entrenamiento del modelo entero. Aqu√≠ es donde ocurre todo el c√°lculo. Una vez entrenado, puede usar su modelo para hacer predicciones sobre nuevos datos. Podemos resumir la construcci√≥n de modelos de Deep learning en Keras de la siguiente manera:\n",
    "<ul>\n",
    "    <li><b>Define tu modelo</b>. Cree un modelo secuencial y a√±ada capas.</li>\n",
    "    <li><b>Compila tu modelo</b>. Especifique la funci√≥n de p√©rdida y los optimizadores y llame a compile() en el modelo.</li>\n",
    "    <li><b>Ajuste a su modelo</b>. Entrene el modelo sobre una muestra de datos llamando a la funci√≥n fit() en el modelo.</li>\n",
    "    <li><b>Haga predicciones</b>. Utilice el modelo para generar predicciones sobre nuevos datos llamando a evaluate() o predict().</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4469, 1775) 4469 Secuencia de entrenamiento\n",
      "(500, 1775) 500 Secuencia de prueba\n"
     ]
    }
   ],
   "source": [
    "print( X_train_cvectorized.shape, len(y_train_hsA), 'Secuencia de entrenamiento' )\n",
    "\n",
    "print( X_test_cvectorized.shape, len(y_test_hsA), 'Secuencia de prueba' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    " \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322113 (1.23 MB)\n",
      "Trainable params: 322113 (1.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "# La clase layer de redes RNN\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "# Como cualquier otra layer de Keras, SimpleRNN procesa lotes de secuencias Numpy.\n",
    "# La entrada es de la forma (batch_size, timesteps, input_features) en vez de (timesteps, input_features).\n",
    "# [muestras, pasos de tiempo, caracter√≠sticas]\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "max_features = 10000  # tama√±o del diccionario de palabras comunes\n",
    "                      # (n√∫mero de palabras a utilizar)\n",
    "maxlen = 1775         # longitud m√°xima de cada secuencia \n",
    "batch_size = 32\n",
    "\n",
    "# Capa embedding\n",
    "# input_dim : tama√±o del vocabulario\n",
    "# output_dim: dimensi√≥n del vector al que se mapea\n",
    "#Se usa un embedding con tama√±o de diccionario a los m√°s de 10,000 y se mapean a dimensi√≥n un vector de dimensi√≥n 32\n",
    "# Las Embedding (incrustaciones) son una excelente manera de lidiar con los problemas de PNL por dos razones. \n",
    "# Primero, ayuda en la reducci√≥n de la dimensionalidad sobre la codificaci√≥n one-hot, ya que podemos controlar la \n",
    "# cantidad de caracter√≠sticas. En segundo lugar, es capaz de comprender el contexto de una palabra para que\n",
    "# palabras similares tengan incrustaciones similares.\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# RNN con una capa Embedding y una capa SimpleRNN que regresa solo una salida para cada secuencia\n",
    "\n",
    "# Resumen de la arquitectura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 - 41s - loss: 0.6781 - acc: 0.5768 - val_loss: 0.6749 - val_acc: 0.5783 - 41s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "28/28 - 34s - loss: 0.6695 - acc: 0.5905 - val_loss: 0.6706 - val_acc: 0.5783 - 34s/epoch - 1s/step\n",
      "Epoch 3/10\n",
      "28/28 - 35s - loss: 0.6642 - acc: 0.6173 - val_loss: 0.6600 - val_acc: 0.6286 - 35s/epoch - 1s/step\n",
      "Epoch 4/10\n",
      "28/28 - 30s - loss: 0.6667 - acc: 0.6283 - val_loss: 0.6603 - val_acc: 0.6298 - 30s/epoch - 1s/step\n",
      "Epoch 5/10\n",
      "28/28 - 30s - loss: 0.6601 - acc: 0.6238 - val_loss: 0.6585 - val_acc: 0.6320 - 30s/epoch - 1s/step\n",
      "Epoch 6/10\n",
      "28/28 - 29s - loss: 0.6528 - acc: 0.6369 - val_loss: 0.6522 - val_acc: 0.6275 - 29s/epoch - 1s/step\n",
      "Epoch 7/10\n",
      "28/28 - 22s - loss: 0.6522 - acc: 0.6297 - val_loss: 0.6517 - val_acc: 0.6286 - 22s/epoch - 798ms/step\n",
      "Epoch 8/10\n",
      "28/28 - 23s - loss: 0.6536 - acc: 0.6249 - val_loss: 0.6519 - val_acc: 0.6298 - 23s/epoch - 810ms/step\n",
      "Epoch 9/10\n",
      "28/28 - 22s - loss: 0.6476 - acc: 0.6347 - val_loss: 0.6474 - val_acc: 0.6309 - 22s/epoch - 783ms/step\n",
      "Epoch 10/10\n",
      "28/28 - 22s - loss: 0.6470 - acc: 0.6336 - val_loss: 0.6474 - val_acc: 0.6320 - 22s/epoch - 795ms/step\n",
      "Tiempo de entrenamiento: 291.2675631046295\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', # algoritmo de optimizaci√≥n que se utiliza durante el entrenamiento del modelo. En este caso, 'rmsprop' se refiere a \"Root Mean Square Propagation\", que es un algoritmo de optimizaci√≥n popular en el campo del aprendizaje profundo.\n",
    "    loss='binary_crossentropy', # funci√≥n de p√©rdida (loss function) utilizada durante el entrenamiento del modelo\n",
    "    # En particular, binary_crossentropy se utiliza en problemas de clasificaci√≥n binaria\n",
    "    # Mide la discrepancia entre las probabilidades predichas por el modelo y las etiquetas reales (objetivos) de los datos de entrenamiento.\n",
    "    # Cuanto menor sea el valor de la p√©rdida, mejor ser√° el ajuste del modelo a los datos de entrenamiento\n",
    "    metrics=['acc']\n",
    ")\n",
    "# optimizer='rmsprop' significa que durante el entrenamiento del modelo de secuencia, se utilizar√° el algoritmo de optimizaci√≥n \n",
    "# RMSprop para ajustar los pesos y sesgos de la red neuronal con el objetivo de minimizar la funci√≥n de p√©rdida y mejorar el rendimiento del modelo.\n",
    "# loss='binary_crossentropy' se utiliza en modelos de secuencia para problemas de clasificaci√≥n binaria, y es una medida\n",
    "# de cu√°n bien el modelo se ajusta a los datos de entrenamiento en t√©rminos de la probabilidad de las etiquetas predichas en comparaci√≥n con las etiquetas reales.\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "history = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 61.80%\n",
      "16/16 [==============================] - 3s 120ms/step\n",
      "\t Accuracy 0.618\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# La funci√≥n model.evaluate predice la salida para la entrada dada y luego calcula la funci√≥n de m√©trica \n",
    "# especificada en model.compile y basada en y_true y y_pred y devuelve el valor de m√©trica calculada como salida\n",
    "\n",
    "# make predictions\n",
    "testPredict = model.predict(X_test_cvectorized)\n",
    "# model.predict simplemente devuelve el y_pred\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict.round()))\n",
    "\n",
    "# si usamos model.predict y luego calculamos las m√©tricas uno mismo, el valor de la m√©trica calculada \n",
    "# deber√≠a resultar ser el mismo que model.evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con Stack de RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, None, 32)          2080      \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324193 (1.24 MB)\n",
      "Trainable params: 324193 (1.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 - 82s - loss: 0.6746 - acc: 0.5952 - val_loss: 0.6507 - val_acc: 0.6298 - 82s/epoch - 3s/step\n",
      "Epoch 2/10\n",
      "28/28 - 66s - loss: 0.6546 - acc: 0.6324 - val_loss: 0.6676 - val_acc: 0.6298 - 66s/epoch - 2s/step\n",
      "Epoch 3/10\n",
      "28/28 - 65s - loss: 0.6558 - acc: 0.6324 - val_loss: 0.6465 - val_acc: 0.6309 - 65s/epoch - 2s/step\n",
      "Epoch 4/10\n",
      "28/28 - 66s - loss: 0.6555 - acc: 0.6316 - val_loss: 0.6512 - val_acc: 0.6298 - 66s/epoch - 2s/step\n",
      "Epoch 5/10\n",
      "28/28 - 58s - loss: 0.6502 - acc: 0.6338 - val_loss: 0.6461 - val_acc: 0.6286 - 58s/epoch - 2s/step\n",
      "Epoch 6/10\n",
      "28/28 - 58s - loss: 0.6504 - acc: 0.6338 - val_loss: 0.6466 - val_acc: 0.6298 - 58s/epoch - 2s/step\n",
      "Epoch 7/10\n",
      "28/28 - 51s - loss: 0.6532 - acc: 0.6246 - val_loss: 0.6483 - val_acc: 0.6309 - 51s/epoch - 2s/step\n",
      "Epoch 8/10\n",
      "28/28 - 67s - loss: 0.6458 - acc: 0.6324 - val_loss: 0.6501 - val_acc: 0.6309 - 67s/epoch - 2s/step\n",
      "Epoch 9/10\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con Stack de RNNs\n",
    "\n",
    "model = Sequential()\n",
    "# Capa embedding\n",
    "# input_dim : tama√±o del vocabulario\n",
    "# output_dim: dimensi√≥n del vector al que se mapea\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True)) # Si devolver la √∫ltima salida en la secuencia de salida o la secuencia completa\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "tic = time.time()\n",
    "history_stackRNN = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red de Memoria Corta a Largo Plazo (Long-Term Short Memory, LTSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero m√°ximo de palabras a usar: 10000\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3575 samples, validate on 894 samples\n",
      "Epoch 1/6\n",
      " - 28s - loss: 0.6812 - acc: 0.5801 - val_loss: 0.6807 - val_acc: 0.5783\n",
      "Epoch 2/6\n",
      " - 29s - loss: 0.6771 - acc: 0.5913 - val_loss: 0.6808 - val_acc: 0.5783\n",
      "Epoch 3/6\n",
      " - 31s - loss: 0.6769 - acc: 0.5913 - val_loss: 0.6812 - val_acc: 0.5783\n",
      "Epoch 4/6\n",
      " - 30s - loss: 0.6773 - acc: 0.5913 - val_loss: 0.6813 - val_acc: 0.5783\n",
      "Epoch 5/6\n",
      " - 30s - loss: 0.6760 - acc: 0.5913 - val_loss: 0.6841 - val_acc: 0.5783\n",
      "Epoch 6/6\n",
      " - 31s - loss: 0.6757 - acc: 0.5913 - val_loss: 0.6797 - val_acc: 0.5783\n",
      "tiempo de entrenamiento:  178.82013750076294\n",
      "acc: 55.60%\n",
      "\t Accuracy 0.556\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "print('N√∫mero m√°ximo de palabras a usar:', max_features)\n",
    "\n",
    "# Creamos el modelo con la incrustaci√≥n (embedding)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "\n",
    "# Incluimos una capa LSTM\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Par√°metros de entrenamiento\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "# y entrenamos\n",
    "tic=time.time()\n",
    "history_LSTM = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=6,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('tiempo de entrenamiento: ', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# make predictions\n",
    "testPredict_LSTM = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_LSTM.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes con Unidades Recurrentes con Compuertas (Gated-RU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 326,273\n",
      "Trainable params: 326,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3575 samples, validate on 894 samples\n",
      "Epoch 1/10\n",
      " - 31s - loss: 0.6795 - acc: 0.5841 - val_loss: 0.6810 - val_acc: 0.5783\n",
      "Epoch 2/10\n",
      " - 35s - loss: 0.6770 - acc: 0.5913 - val_loss: 0.6813 - val_acc: 0.5783\n",
      "Epoch 3/10\n",
      " - 39s - loss: 0.6767 - acc: 0.5913 - val_loss: 0.6810 - val_acc: 0.5783\n",
      "Epoch 4/10\n",
      " - 40s - loss: 0.6768 - acc: 0.5913 - val_loss: 0.6809 - val_acc: 0.5783\n",
      "Epoch 5/10\n",
      " - 43s - loss: 0.6766 - acc: 0.5913 - val_loss: 0.6812 - val_acc: 0.5783\n",
      "Epoch 6/10\n",
      " - 39s - loss: 0.6767 - acc: 0.5913 - val_loss: 0.6811 - val_acc: 0.5783\n",
      "Epoch 7/10\n",
      " - 39s - loss: 0.6770 - acc: 0.5913 - val_loss: 0.6823 - val_acc: 0.5783\n",
      "Epoch 8/10\n",
      " - 38s - loss: 0.6771 - acc: 0.5913 - val_loss: 0.6812 - val_acc: 0.5783\n",
      "Epoch 9/10\n",
      " - 35s - loss: 0.6769 - acc: 0.5913 - val_loss: 0.6813 - val_acc: 0.5783\n",
      "Epoch 10/10\n",
      " - 37s - loss: 0.6768 - acc: 0.5913 - val_loss: 0.6809 - val_acc: 0.5783\n",
      "Tiempo de entrenamiento: 376.0974667072296\n",
      "acc: 55.60%\n",
      "\t Accuracy 0.556\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "# Capa embedding\n",
    "# input_dim : tama√±o del vocabulario\n",
    "# output_dim: dimensi√≥n del vector al que se mapea\n",
    "\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32))\n",
    "# comentar la siguiente linea para evaluar dropout \n",
    "model.add(GRU(32))\n",
    "# descomentar la siguiente linea para evaluar dropout \n",
    "#model.add(GRU(32, dropout=.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "tic = time.time()\n",
    "history_GRU = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# make predictions\n",
    "testPredict_GRU = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_GRU.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 324,193\n",
      "Trainable params: 324,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3575 samples, validate on 894 samples\n",
      "Epoch 1/10\n",
      " - 30s - loss: 0.6902 - acc: 0.5676 - val_loss: 0.6819 - val_acc: 0.5783\n",
      "Epoch 2/10\n",
      " - 29s - loss: 0.6797 - acc: 0.5910 - val_loss: 0.6914 - val_acc: 0.5783\n",
      "Epoch 3/10\n",
      " - 26s - loss: 0.6788 - acc: 0.5863 - val_loss: 0.6816 - val_acc: 0.5783\n",
      "Epoch 4/10\n",
      " - 26s - loss: 0.6770 - acc: 0.5894 - val_loss: 0.6817 - val_acc: 0.5794\n",
      "Epoch 5/10\n",
      " - 28s - loss: 0.6757 - acc: 0.5894 - val_loss: 0.6860 - val_acc: 0.5794\n",
      "Epoch 6/10\n",
      " - 27s - loss: 0.6774 - acc: 0.5835 - val_loss: 0.6817 - val_acc: 0.5794\n",
      "Epoch 7/10\n",
      " - 30s - loss: 0.6760 - acc: 0.5927 - val_loss: 0.6811 - val_acc: 0.5783\n",
      "Epoch 8/10\n",
      " - 27s - loss: 0.6771 - acc: 0.5877 - val_loss: 0.6800 - val_acc: 0.5817\n",
      "Epoch 9/10\n",
      " - 26s - loss: 0.6756 - acc: 0.5922 - val_loss: 0.6900 - val_acc: 0.5761\n",
      "Epoch 10/10\n",
      " - 26s - loss: 0.6800 - acc: 0.5782 - val_loss: 0.6873 - val_acc: 0.5805\n",
      "Tiempo de entrenamiento: 278.24513602256775\n",
      "acc: 55.80%\n",
      "\t Accuracy 0.558\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con Stack de RNNs\n",
    "\n",
    "# La clase layer de redes RNN\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "# Como cualquier otra layer de Keras, SimpleRNN procesa lotes de secuencias Numpy.\n",
    "# La entrada es de la forma (batch_size, timesteps, input_features) en vez de (timesteps, input_features).\n",
    "# [muestras, pasos de tiempo, caracter√≠sticas]\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "max_features = 10000  # tama√±o del diccionario de palabras comunes\n",
    "                      # (n√∫mero de palabras a utilizar)\n",
    "maxlen = 1775         # longitud m√°xima de cada secuencia \n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Capa embedding\n",
    "# input_dim : tama√±o del vocabulario\n",
    "# output_dim: dimensi√≥n del vector al que se mapea\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "history_stackRNN = model.fit(\n",
    "    X_train, y_train_hsA,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos basados en atenci√≥n y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "    \n",
    "    https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470\n",
    "        \n",
    "        http://personal.cimat.mx:8181/~mrivera/cursos/aprendizaje_profundo/RNN_LTSM/introduccion_rnn.html\n",
    "                \n",
    "                https://unipython.com/prediccion-con-series-temporales-con-lstm-redes-neuronales-recurrentes/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
