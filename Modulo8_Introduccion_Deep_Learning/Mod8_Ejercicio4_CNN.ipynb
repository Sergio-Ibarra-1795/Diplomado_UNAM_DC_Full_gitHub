{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#03997A\"> Diplomado en Ciencia de datos UNAM </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Dr: Alejandro Pimentel  </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Modulo 8 Introducción al Deep Learning </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Ejercicio 4 CNN  Alumno: Ibarra Ramírez Sergio </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "c:\\Users\\Sergio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X,y = fetch_openml('mnist_784', as_frame=False, return_X_y=True)\n",
    "\n",
    "X = normalize(X).reshape(-1,28,28,1)\n",
    "\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]\n",
    "\n",
    "codificador = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "y_train = codificador.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = codificador.transform(y_test.reshape(-1,1))\n",
    "\n",
    "X_train = tf.constant(X_train, dtype=tf.float32)\n",
    "X_test = tf.constant(X_test, dtype=tf.float32)\n",
    "y_train = tf.constant(y_train, dtype=tf.float32)\n",
    "y_test = tf.constant(y_test, dtype=tf.float32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "batch_size = 100 # Hiperparámetro\n",
    "train_dataset = train_dataset.shuffle(batch_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.random.normal([10]))\n",
    "W = tf.Variable(tf.random.normal([1568,10]))\n",
    "\n",
    "filtros1 = tf.Variable(tf.random.normal([4,4,1,16])) # (alto,ancho,canales,num_filtros)\n",
    "b_conv1 = tf.Variable(tf.random.normal([16]))\n",
    "\n",
    "filtros2 = tf.Variable(tf.random.normal([4,4,16,32])) # (alto,ancho,canales,num_filtros)\n",
    "b_conv2 = tf.Variable(tf.random.normal([32]))\n",
    "\n",
    "optimizador = tf.keras.optimizers.experimental.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(14.883716, shape=(), dtype=float32)\n",
      "tf.Tensor(3.3829992, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8502724, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6319265, shape=(), dtype=float32)\n",
      "tf.Tensor(2.507591, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4456027, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4044218, shape=(), dtype=float32)\n",
      "tf.Tensor(2.384183, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3456023, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3303554, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for _ in range(epochs):\n",
    "  loss_epoch = 0\n",
    "  for x,y in train_dataset:\n",
    "    with tf.GradientTape() as gt:\n",
    "\n",
    "      salida_conv1 = tf.nn.conv2d(x,filtros1,[1,2,2,1],\"SAME\")\n",
    "      salida_conv1 += b_conv1\n",
    "      salida_activacion1 = tf.nn.relu(salida_conv1) # Capa no lineal intermedia\n",
    "\n",
    "      salida_conv2 = tf.nn.conv2d(salida_activacion1,filtros2,[1,2,2,1],\"SAME\")\n",
    "      salida_conv2 += b_conv2\n",
    "      #salida_activacion2 =tf.nn.relu(salida_conv2) # necesita el relu?\n",
    "\n",
    "      salidaPlana = tf.reshape(salida_conv2,[-1,1568])\n",
    "\n",
    "      operacion_matricial = tf.matmul(salidaPlana,W)+b # Primera capa\n",
    "\n",
    "      x_ent = tf.nn.softmax_cross_entropy_with_logits(\n",
    "          logits = operacion_matricial,\n",
    "          labels = y\n",
    "      )\n",
    "\n",
    "      loss = tf.reduce_mean(x_ent)\n",
    "      optimizador.minimize(loss,[W,b,filtros1,b_conv1, filtros2, b_conv2],gt) # Poderosa\n",
    "\n",
    "    loss_epoch += loss/len(train_dataset)\n",
    "  print(loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.1675, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "salida_conv1 = tf.nn.conv2d(X_test,filtros1,[1,2,2,1],\"SAME\")\n",
    "salida_conv1 += b_conv1\n",
    "salida_activacion1 = tf.nn.relu(salida_conv1) # Capa no lineal intermedia\n",
    "salida_conv2 = tf.nn.conv2d(salida_activacion1,filtros2,[1,2,2,1],\"SAME\")\n",
    "salida_conv2 += b_conv2\n",
    "#salida_activacion2 =tf.nn.relu(salida_conv2) # necesita el relu?\n",
    "\n",
    "salidaPlana = tf.reshape(salida_conv2,[-1,1568])\n",
    "\n",
    "operacion_matricial = tf.matmul(salidaPlana,W)+b # Primera capa\n",
    "\n",
    "probs = tf.nn.softmax(operacion_matricial)\n",
    "\n",
    "max_preds = tf.argmax(probs,1)\n",
    "max_trues = tf.argmax(y_test,1)\n",
    "\n",
    "numCorrectos = tf.equal(max_preds,max_trues)\n",
    "acc = tf.reduce_mean(tf.cast(numCorrectos,tf.float32)) # Tengo que convertirlo porque el original es booleano\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
