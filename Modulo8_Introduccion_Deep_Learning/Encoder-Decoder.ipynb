{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"#03997A\"> Diplomado en Ciencia de datos UNAM </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Dr: Alejandro Pimentel  </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Modulo 8 Introducción al Deep Learning </font>\n",
    "\n",
    "##### <font color=\"#03997A\"> Tema 5 Encoder-Decoer  Alumno: Ibarra Ramírez Sergio </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_oracion = 300\n",
    "num_palabras = 5000\n",
    "emb_dim = 200\n",
    "\n",
    "#### De que tamanio va ser el vector con que se representarña la oración total\n",
    "h_dim = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras vectorizadas, vana ser las entradas, pasadas por un embeding (Es como se hacía en el secuencial en donde se definnia como primera capa un embeing donde se especificaba su tamanio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 200) dtype=float32 (created by layer 'embedding')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_codificador = tf.keras.layers.Input(shape=(None,))\n",
    "embeddings = tf.keras.layers.Embedding(num_palabras,emb_dim)\n",
    "palabras_vectorizadas = embeddings(entradas_codificador)\n",
    "palabras_vectorizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va ausar la arquitectura GRU como encodficiador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 600) dtype=float32 (created by layer 'gru')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codificador_gru = tf.keras.layers.GRU(h_dim,recurrent_dropout=0.5,return_state=True)\n",
    "salida_cod, estado_cod = codificador_gru(palabras_vectorizadas)\n",
    "salida_cod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x2b9199336a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_codificador = tf.keras.models.Model(entradas_codificador,estado_cod)\n",
    "modelo_codificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y las entradas del decodificador será obviamente las salidas del codificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 600) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_decodificador = tf.keras.layers.Input(shape=salida_cod.shape)\n",
    "entradas_decodificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po tro lado return_sequences retorna una matriz como secuencia de palabras de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.rnn.gru.GRU at 0x2b90ae89840>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodificador_gru = tf.keras.layers.GRU(h_dim,recurrent_dropout=0.5, return_sequences=True)\n",
    "decodificador_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 600) dtype=float32 (created by layer 'gru_1')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "entrada_estado_decod = tf.keras.layers.Input(shape=(h_dim,))\n",
    "salidas_decod = decodificador_gru(entradas_decodificador,initial_state=entrada_estado_decod)\n",
    "salidas_decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x2b919a6ea40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodificador_densa = tf.keras.layers.Dense(num_palabras, activation='softmax')\n",
    "decodificador_densa \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la ultima capa despues de las primeras dos RNN (En este caso GRU) será una Dense de tipo SOFTMAX, en donde la salida de la GRU Decoder se le pasa al a densa de SOFTMAX para predecir cada caso la palabras más probable siguiente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x2b919a6e620>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salidas_decod = decodificador_densa(salidas_decod)\n",
    "modelo_decodificador = tf.keras.models.Model([entrada_estado_decod,entradas_decodificador],salidas_decod)\n",
    "modelo_decodificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
