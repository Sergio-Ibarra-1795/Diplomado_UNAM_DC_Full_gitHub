{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Árboles de Clasificación"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from pyspark import SparkContext\n","from pyspark.sql import SQLContext"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-01-27 05:19:17--  https://github.com/omarmendoza564/datos/raw/main/datos/OnTimeDB.zip\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/omarmendoza564/datos/main/datos/OnTimeDB.zip [following]\n","--2023-01-27 05:19:17--  https://raw.githubusercontent.com/omarmendoza564/datos/main/datos/OnTimeDB.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 484951 (474K) [application/zip]\n","Saving to: ‘/home/omendoza_dcd04/OnTimeDB.zip’\n","\n","/home/omendoza_dcd0 100%[===================>] 473.58K  --.-KB/s    in 0.04s   \n","\n","2023-01-27 05:19:17 (12.4 MB/s) - ‘/home/omendoza_dcd04/OnTimeDB.zip’ saved [484951/484951]\n","\n","Archive:  /home/omendoza_dcd04/OnTimeDB.zip\n","   creating: /home/omendoza_dcd04/OnTimeDB/\n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00000.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00001.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00002.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00003.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00004.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00005.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/.part-00006.crc  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00000  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00001  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00002  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00003  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00004  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00005  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/part-00006  \n","  inflating: /home/omendoza_dcd04/OnTimeDB/_SUCCESS  \n","total 3276\n","drwxrwxr-x 2 root           root             4096 Nov 23  2021 .\n","drwxr-xr-x 8 omendoza_dcd04 omendoza_dcd04   4096 Jan 27 05:19 ..\n","-rw-r--r-- 1 root           root             7428 Jul 18  2018 .part-00000.crc\n","-rw-r--r-- 1 root           root             2256 Jul 18  2018 .part-00001.crc\n","-rw-r--r-- 1 root           root             3184 Jul 18  2018 .part-00002.crc\n","-rw-r--r-- 1 root           root             2916 Jul 18  2018 .part-00003.crc\n","-rw-r--r-- 1 root           root             6948 Jul 18  2018 .part-00004.crc\n","-rw-r--r-- 1 root           root             2012 Jul 18  2018 .part-00005.crc\n","-rw-r--r-- 1 root           root             1076 Jul 18  2018 .part-00006.crc\n","-rw-r--r-- 1 root           root                0 Jul 18  2018 _SUCCESS\n","-rw-r--r-- 1 root           root           949404 Jul 18  2018 part-00000\n","-rw-r--r-- 1 root           root           287594 Jul 18  2018 part-00001\n","-rw-r--r-- 1 root           root           406415 Jul 18  2018 part-00002\n","-rw-r--r-- 1 root           root           372196 Jul 18  2018 part-00003\n","-rw-r--r-- 1 root           root           888266 Jul 18  2018 part-00004\n","-rw-r--r-- 1 root           root           256021 Jul 18  2018 part-00005\n","-rw-r--r-- 1 root           root           136582 Jul 18  2018 part-00006\n"]}],"source":["#Leer el contenido de una carpeta \n","#Para leer de HDFS usar\n","# hdfs:///tmp/dcd/OnTimeDB\n","#Para leer de local usar\n","# file:/home/cloudera/dcd/OnTimeDB/\n","\n","## Descargar archivo zip y subir al cluster\n","!wget https://github.com/omarmendoza564/datos/raw/main/datos/OnTimeDB.zip -O /home/omendoza_dcd04/OnTimeDB.zip\n","!unzip -o /home/omendoza_dcd04/OnTimeDB.zip -d /home/omendoza_dcd04/\n","!ls -la /home/omendoza_dcd04/OnTimeDB\n","!hdfs dfs -mkdir /tmp/dcd/OnTimeDB\n","!hdfs dfs -put /home/omendoza_dcd04/OnTimeDB/ /tmp/dcd/"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["30466"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["bd = sqlContext.read.csv(\"hdfs:///tmp/dcd/OnTimeDB/\", inferSchema=True, header=True)\n","sqlContext.registerDataFrameAsTable(bd, \"bd\")\n","bd.count()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["[('Year', 'int'),\n"," ('Month', 'int'),\n"," ('DayofMonth', 'int'),\n"," ('DayOfWeek', 'int'),\n"," ('CRSDepTime', 'int'),\n"," ('UniqueCarrier', 'string'),\n"," ('TailNum', 'string'),\n"," ('ArrDelay', 'double'),\n"," ('DepDelay', 'double'),\n"," ('Origin', 'string'),\n"," ('Dest', 'string'),\n"," ('Distance', 'double'),\n"," ('Cancelled', 'double'),\n"," ('Diverted', 'double'),\n"," ('CarrierDelay', 'double'),\n"," ('WeatherDelay', 'double'),\n"," ('NASDelay', 'double'),\n"," ('SecurityDelay', 'double'),\n"," ('LateAircraftDelay', 'double'),\n"," ('LogD', 'double'),\n"," ('Retraso', 'int'),\n"," ('RetrasoNeto', 'double'),\n"," ('Horario', 'int')]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Ver las variables disponibles\n","bd.dtypes"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 27:=============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------+------------------+-----+\n","|UniqueCarrier|IndexUniqueCarrier|count|\n","+-------------+------------------+-----+\n","|           AA|               0.0| 8853|\n","|           UA|               1.0| 6112|\n","|           WN|               2.0| 5395|\n","|           DL|               3.0| 4239|\n","|           VX|               4.0| 1703|\n","|           NK|               5.0| 1581|\n","|           F9|               6.0| 1295|\n","|           OO|               7.0| 1166|\n","|           B6|               8.0|  121|\n","|           EV|               9.0|    1|\n","+-------------+------------------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Agregar una variable numerica (IndexUniqueCarrier) basada en la variable alfanumerica \n","#de la compañia que opera el vuelo (UniqueCarrier) \n","\n","from pyspark.ml.feature import StringIndexer\n","\n","indexer = StringIndexer(inputCol='UniqueCarrier',outputCol='IndexUniqueCarrier') #el índice empieza en el 0!\n","bd1=indexer.fit(bd).transform(bd)\n","\n","#Se muestra el numero de vuelos operados por cada compañia, la variable IndexUniqueCarrier \n","#ya se puede utilizar en el modelo\n","\n","bd1.groupBy('UniqueCarrier','IndexUniqueCarrier').count().sort('IndexUniqueCarrier').show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Ajuste del modelo"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["[('label', 'double'), ('features', 'vector'), ('label2', 'double')]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.ml.feature import VectorAssembler, StringIndexer\n","from pyspark.sql.functions import col\n","\n","#Crear un arreglo de variables predictoras llamdo 'features'\n","#ArrDelay representa el numero de minutos que un vuelo tiene de retraso\n","#Si un vuelo llega con mas de 15 minutos de retraso la variable 'Retraso' tiene valor 1 \n","#Renombrar la variable objetivo (Retraso) como 'label'\n","\n","#En el caso particular de los árboles de clasificación, la variable objetivo debe ser de tipo doble. \n","#Por lo tanto, transformar la variable a tipo doble. \n","#Además, la variable debe estar convertida a través de la función stringIndexer \n","#para poder ser analizada por el modelo\n","#Por lo tanto, la variable de trabajo, en este caso, será 'label2'\n","\n","\n","a1  = VectorAssembler(\n","    inputCols=['DepDelay','Distance','DayOfWeek',\n","               'CRSDepTime','IndexUniqueCarrier'],\n","    outputCol='features')\n","\n","bd2 = a1.transform(bd1).select(col(\"Retraso\").cast('double').alias(\"label\"),'features')\n","\n","stringIndexer = StringIndexer(inputCol = 'label', outputCol = 'label2')\n","sI = stringIndexer.fit(bd2)\n","bd2 = sI.transform(bd2)\n","bd2.dtypes\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+------+\n","|label|            features|label2|\n","+-----+--------------------+------+\n","|  0.0|[-5.0,1235.0,4.0,...|   0.0|\n","+-----+--------------------+------+\n","only showing top 1 row\n","\n"]}],"source":["#Mostrar un solo renglon de la BD\n","bd2.show(1)"]},{"cell_type":"markdown","metadata":{},"source":["### Partición Test - Train"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Renglones de la BD Train:  21219\n","Renglones de la BD Test:  9247\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#70% Train\n","#30% Test\n","(bd_train, bd_test) = bd2.randomSplit([0.7, 0.3],seed=123)\n","print(\"Renglones de la BD Train: \", bd_train.count())\n","print(\"Renglones de la BD Test: \",bd_test.count())"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Utilizamos el modelo DecisionTreeClassifier para generar un prediccion basado en los features\n","# disponibles\n","#Con una profundidad (maxDepth) de 5\n","#Espeficiar la variable objetivo (labelCol)\n","\n","from pyspark.ml.classification import DecisionTreeClassifier as DTC\n","\n","rt = DTC(maxDepth=5, labelCol = 'label2')\n","\n","model = rt.fit(bd_train)\n","pred = model.transform(bd_train)\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+------+---------------+--------------------+----------+\n","|label|            features|label2|  rawPrediction|         probability|prediction|\n","+-----+--------------------+------+---------------+--------------------+----------+\n","|  0.0|[-21.0,868.0,6.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-20.0,1440.0,6.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-19.0,1440.0,3.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-18.0,602.0,5.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-17.0,888.0,6.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-17.0,1440.0,1.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-17.0,1744.0,1.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-16.0,641.0,6.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-16.0,868.0,6.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,731.0,1.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,868.0,3.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,888.0,4.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,888.0,5.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,1464.0,6.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,1514.0,2.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-15.0,1514.0,4.0...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-14.0,236.0,2.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-14.0,236.0,3.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-14.0,236.0,4.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","|  0.0|[-14.0,255.0,3.0,...|   0.0|[13665.0,985.0]|[0.93276450511945...|       0.0|\n","+-----+--------------------+------+---------------+--------------------+----------+\n","only showing top 20 rows\n","\n"]}],"source":["#La columna rawPrediction, está especificando el número de casos negativos y  positivos \n","#en cada uno de los nodos terminales pertinentes para cada observación. \n","#[Casos para 0, Casos para 1]\n","\n","#El campo probability muestra la probabilidad de ser 0 o 1  \n","#El valor predicho, estableciendo un punto de corte del 50% se muestra en el campo prediction\n","\n","pred.show()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["AUC= 0.8966334172544019\n"]}],"source":["#Validar el modelo\n","#Calcular el Areba bajo la curva \n","#El AUC proporciona una medición agregada del rendimiento en todos los umbrales de clasificación \n","#posibles\n","\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator as BCE\n","print('AUC=',BCE(metricName=\"areaUnderROC\", rawPredictionCol = 'probability').evaluate(pred))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 66:>                                                         (0 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+-----+\n","|         probability|count|\n","+--------------------+-----+\n","|           [1.0,0.0]|    2|\n","|[0.65116279069767...|   43|\n","|[0.35526315789473...|   76|\n","|[0.25984251968503...|  127|\n","|[0.66666666666666...|  144|\n","|[0.50531914893617...|  188|\n","|[0.09150326797385...|  306|\n","|[0.46683673469387...|  392|\n","|[0.27331887201735...|  461|\n","|[0.70650032829940...| 1523|\n","|[0.01118838826731...| 3307|\n","|[0.93276450511945...|14650|\n","+--------------------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Generar una tabla de frecuencias de las distintan probabilidades, es decir de los distintos \n","#nodos terminales\n","\n","pred.groupBy('probability').count().sort('count').show(50)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 69:=============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-----+----------+-----+\n","|label|prediction|count|\n","+-----+----------+-----+\n","|  1.0|       1.0| 4235|\n","|  0.0|       1.0|  434|\n","|  1.0|       0.0| 1588|\n","|  0.0|       0.0|14962|\n","+-----+----------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Generar la matriz de confusion\n","pred.groupBy('label','prediction').count().show()\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Se realizaron 21219 inspeciones y existen 19197 predicciones existosas\n","Esta es una tasa de éxito del 90.47080446769404%\n"]}],"source":["#Generar algunas estadísticas para tener una idea de cómo fueron las predicciones\n","\n","numSuccesses = pred.where(\"\"\"(prediction = 0.0 AND label2 = 0.0) OR (prediction = 1.0 AND label2 = 1.0)\"\"\").count()\n","numInspections = pred.count()\n","\n","print (\"Se realizaron\", numInspections, \"inspeciones y existen\", numSuccesses, \"predicciones existosas\")\n","print (\"Esta es una tasa de éxito del\", str((float(numSuccesses) / float(numInspections)) * 100) + \"%\")"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true},"outputs":[],"source":["# DecisionTreeClassifier(featuresCol=\"features\",\n","#    labelCol=\"label\",\n","#    predictionCol=\"prediction\",\n","#    probabilityCol=\"probability\",\n","#    rawPredictionCol=\"rawPrediction\",\n","#    maxDepth=5,\n","#    maxBins=32,\n","#    minInstancesPerNode=1,\n","#    minInfoGain=0.0,\n","#    maxMemoryInMB=256,\n","#    impurity=\"gini\"  / impurity=\"entropy\" )"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["AUC= 0.9990185263935085\n"]}],"source":["#Cambiando las propiedades del ejecutamos un nuevo arbol con una profundidad de 20\n","rt = DTC(maxDepth=20, labelCol = 'label2')\n","model = rt.fit(bd_train)\n","pred = model.transform(bd_train)\n","\n","#Evaluar el modelo con AUC que ahora ha aumentado\n","print('AUC=',BCE(metricName=\"areaUnderROC\", rawPredictionCol = 'probability').evaluate(pred))"]},{"cell_type":"markdown","metadata":{},"source":["### Validación externa"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC= 0.8193169919620452\n"]}],"source":["#Validación externa con la BD test\n","\n","predtest = model.transform(bd_test)\n","\n","print('AUC=',BCE(metricName=\"areaUnderROC\",rawPredictionCol = 'probability').evaluate(predtest))"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":2}